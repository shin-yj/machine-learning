{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files # text로부터 숫자로 바꾸는 것 (텍스트 분석을 위해)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files('data-files/aclImdb/train') # 지정된 폴더(Train)의 하위 폴더가 타겟 레이블-> neg, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
      "25000\n",
      "b\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\"\n",
      "['neg', 'pos']\n",
      "[1 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train.keys())\n",
    "print(len(reviews_train['data']))\n",
    "print(reviews_train['data'][0])\n",
    "print(reviews_train['target_names'])\n",
    "print(reviews_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = reviews_train['data'], reviews_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 [12623, 24836, 13781, 1326, 8484] 5000\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "size = int(len(X_train) * 0.2)\n",
    "# idxes = np.random.randint(0, len(X_train), size) # 20%의 데이터만 샘플링 # randint는 비복원추출만 가능, 복원 추출 불가\n",
    "idxes = random.sample(range(len(X_train)), size) # 복원 추출 가능\n",
    "print( len(idxes), idxes[:5], len(np.unique(idxes)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000,), (5000,))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train2, y_train2 = [X_train[i] for i in idxes], [y_train[i] for i in idxes]\n",
    "X_train2, y_train2 = np.array(X_train)[idxes], np.array(y_train)[idxes] # np.array로 만든 후 정렬\n",
    "X_train2.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Friz Freleng's 'Speedy Gonzalez' was the second cartoon to feature the title character after Robert McKimson's 'Cat-tails for Two'. In that cartoon, Speedy has been an ugly little creature with a big gold tooth but by his second appearance the famous design had already been adopted. Despite looking significantly more handsome, Speedy never developed into much of a character. A big hat, tremendous speed and a bad Mexican accent do not a classic character make and that's pretty much all Speedy ever had going for him. Nevertheless, the cocky little mouse proved enormously popular and went on to star in many shorts including some truly abysmal films from the studio's latter days. While these early Speedy shorts are better than those later atrocities in which he was frequently (rather oddly) paired up with Daffy Duck, they still leave much to be desired, relying on predictable gags usually based around a similar chase formula. In this self-titled episode, Speedy is recruited by some other mice to steal cheese for them from the local factory which happens to be guarded by Sylvester the cat. Although he brings the extra weight of a star turn to the cartoon, Sylvester's role here could just as easily been filled by any other generic cartoon cat. His personality is sapped by his being forced into the predictable. undemanding role of pursuer. This was always a problem in the Tweety cartoons too but Speedy makes an even duller adversary thanks to his detestable cockiness and the blatant impossibility of his capture. Poor old Sylvester would be forced to appear alongside Speedy for many years to come. Despite it following a pretty basic formula and featuring minimal laughs, 'Speedy Gonzalez' won an Oscar and a thoroughly undeserving star was born.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2 = np.array([x.replace(b'<br />', b' ') for x in X_train2]) # b = data를 각 1byte형식의 array로 만들어줌 # r이면 \\n 안먹음\n",
    "# X_train2 = map(lambda x: x.replace(b'<br />', b' '), X_train2)\n",
    "# X_train2 = np.array(list(X_train3)) # map인경우 리스트, np.array를 해줘야 프린트 결과물이 나옴\n",
    "X_train2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2505, 2495], dtype=int64))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train2, return_counts=True) #불균형성 확인 -> 균형적인 편"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files('data-files/aclImdb/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = reviews_test['data'], reviews_test['target']\n",
    "size = int(len(X_test) * 0.2)\n",
    "idxes = random.sample(range(len(X_test)), size)\n",
    "len(np.unique(idxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = np.array([ X_test[idx] for idx in idxes])\n",
    "y_test2 = np.array([ y_test[idx] for idx in idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2544, 2456], dtype=int64))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test2, return_counts=True) # 비율 상 문제 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = np.array([ x.replace(b'<br />', b' ') for x in X_test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hayao Miyazaki\\'s latest and eighth film for Studio Ghibili, \"Gake No Ue No Ponyo\" (Ponyo on the Cliff by the Sea) is a wonderfully fun and imaginative look at childhood. At a time when it seems that film animation has been dominated by Disney/Pixar\\'s CGI masterpieces, it is both refreshing and comforting to know that Miyazaki is still relying on traditional hand-drawn animation to tell his charming and enchanting stories.   The story revolves around the friendship between a magical sea sprite/goldfish and the human child that she encounters during a curious outing to see the human world. The human child, Sosuke (Doi Hiroki) lives in a small house on a cliff overlooking a small port city in Southern Japan (based on Seto Island) where he lives with his young mom, Lisa (Yamaguchi Tomoko). Sosuke names the strange goldfish \"Ponyo\" and takes it to the daycare/nursing center that Lisa works at. Ponyo is definitely not your typical goldfish and soon begins to adapt and take on human aspects (she develops human speech and an appetite for ham meat) by sampling some blood from a cut on Sosuke\\'s finger.   Yet just as Sosuke and Ponyo begin to develop a bond, Ponyo is taken back by her father, Fujimoto (Tokoro Joji) who is a former human who has rejected the surface world and is now attempting to collect and develop magical elixirs taken from the sea that aid him in repairing and rejuvenating the world\\'s oceans.  Ponyo\\'s desire to become human has become so strong however that Fujimoto is unable to contain her anymore and she takes on a more human appearance and breaks free from her water world home and goes back to see Sosuke.   During her breakout, Ponyo unintentionally releases Fujimoto\\'s cache of magical elixirs which unleashes all sorts of magical sea creatures that causes a violent storm in the seas surrounding Sosuke\\'s town. Desperate to resolve Ponyo\\'s rebellion, he soon calls upon the help of his beautiful wife, Ponyo\\'s mother - the water elemental, Mother/Lady of the Sea (Amami Yuki).   As with his past films, Miyazaki\\'s \"Gake No Ue No Ponyo\" touches upon various themes of ecology and environmentalism, this time focusing on the health and vitality of the world\\'s oceans. The opening sequence is at times sobering when Ponyo encounters a drudging vessel which is scraping the ocean\\'s floor, uncovering mountains of garbage and debris. One can understand the anger and frustration of the character of Fujimoto who has spent his lifetime trying to repair the damage civilization is doing to its oceans, yet finding it an daunting and almost fruitless endeavor.  Enough can not be said of the remarkable animation in this film. It is at times bizarre and outrageous but at the same time charming and curious. Clearly Miyazaki wanted to capture the sense and style of a child\\'s imagination. The art style has the appearance of crayon/pencil drawings and is wonderfully colorful and fanciful. It is almost like a child\\'s color book come to life.  Child actors Nara Yuria and Doi Hiroki do great work as Ponyo and Sosuke. They bring adorable charm to their roles. Nara Yuria in particular sounds so darn cute as Ponyo that it is little wonder that Doi\\'s Sosuke falls for the magical girl. Former campaign girl/model and actress Yamaguchi Tomoko (Shichinin No Otaku, Swallowtail) is also very good in her role as Sosuke\\'s modern mom, Lisa. I was a bit confused at first by her character as I initially thought she was Sosuke\\'s older sister. It also didn\\'t help that Sosuke kept referring to her as \"Lisa\" rather than Mom but I guess it is perhaps a sign of the times and an indicator of the modern Japanese family (in the anime series Crayon Shinchan, Shinnosuke also refers to his mom by first name as well).  80s comedian Tokoro Joji sounds totally different as the serious Fujimoto but wisely doesn\\'t make his character sound cartoony villainous or goofy menacing. While we don\\'t get to know his character more, former pro-baseball player and actor Nagashima Kazushige ( who portrays Sosuke\\'s father Koichi) also delivers some nice voice work. The opening theme \"Umi No Okasan\" by Japanese soprano Masako Hayashi is simply beautiful and stirring. In contrast the Fujimaki Fujioka and Nozomi Ohashi \"Geke No Ue No Ponyo\" theme is light and amusing and evokes images of a traditional Japanese nursery rhyme. During one brilliant sequence the soundtrack takes on an almost Wagnerian operatic sound with music that sounds like \"Die Walk\\xc3\\xbcre\".  The film is not perfect however and does suffer from moments where the central story of Ponyo and Sosuke takes a back seat to some of Miyazaki\\'s overwhelming fantastical visuals. I also had wished we had more time to explore Fujimoto\\'s back-story as well as the relationship between Sosuke and his father.  Like \"Kiki\\'s Delivery Service/Majo No Takkyubin\", \"Howl\\'s Moving Castle\", \"Princess Momonoke/Momonoke Hime\" and \"My Neighbor Totoro/Tonari No Totoro\", \"Gake No Ue No Ponyo\" is another Miyazaki classic that is a marvelous feast for the eyes. Like a modern day fairytale, the film tells a timeless story of friendship and love that will surely be cherished in years to come.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = ['The fool doth think he is wise, ', 'but the wise man knows himself to be a fool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer() # 문장 -> 단어 사전 만들기 + 단어별 빈도수 계산하는 도구\n",
    "cv.fit(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 9,\n",
       " 'fool': 3,\n",
       " 'doth': 2,\n",
       " 'think': 10,\n",
       " 'he': 4,\n",
       " 'is': 6,\n",
       " 'wise': 12,\n",
       " 'but': 1,\n",
       " 'man': 8,\n",
       " 'knows': 7,\n",
       " 'himself': 5,\n",
       " 'to': 11,\n",
       " 'be': 0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>doth</th>\n",
       "      <th>fool</th>\n",
       "      <th>he</th>\n",
       "      <th>himself</th>\n",
       "      <th>is</th>\n",
       "      <th>knows</th>\n",
       "      <th>man</th>\n",
       "      <th>the</th>\n",
       "      <th>think</th>\n",
       "      <th>to</th>\n",
       "      <th>wise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   be  but  doth  fool  he  himself  is  knows  man  the  think  to  wise\n",
       "0   0    0     1     1   1        0   1      0    0    1      1   0     1\n",
       "1   1    1     0     1   0        1   0      1    1    1      0   1     1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# print(cv.transform(test_words)) # 0번째 문장에 2번(doth) 하나 ..\n",
    "print(cv.transform(test_words).toarray()) # 0번째 문장에 0번  x 3번,4,5번 존재\n",
    "pd.DataFrame(cv.transform(test_words).toarray(), columns=sorted(cv.vocabulary_, key=lambda key: cv.vocabulary_[key])) # 빈도수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(X_train2)\n",
    "X_train3 = cv.transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 38326)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train3.toarray().shape)# 문장 5000, 단어 38326개\n",
    "print(X_train3.toarray()[:5])\n",
    "# print(X_train3)\n",
    "# print(cv.vocabulary_) # 각각의 단어에 대해 번호를 다 붙인다\n",
    "# cv.get_feature_names() # 정렬된 컬럼 이름들만 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9934\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000, C=0.1)\n",
    "lr.fit(X_train3, y_train2)\n",
    "print(lr.score(X_train3, y_train2))\n",
    "# print(lr.score(X_test3, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test3 = cv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8612\n"
     ]
    }
   ],
   "source": [
    "print(lr.score(X_test3, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9190131094383963\n",
      "0.9284378329031202\n"
     ]
    }
   ],
   "source": [
    "print(average_precision_score(y_test2,lr.predict_proba(X_test3)[:, 1]))\n",
    "print(roc_auc_score(y_test2, lr.predict_proba(X_test3)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11327\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=5) # 5회 이상 발견된 데이터만 포함\n",
    "cv.fit(X_train2)\n",
    "print(len(cv.get_feature_names()))\n",
    "X_train3 = cv.transform(X_train2)\n",
    "X_test3 = cv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9884\n",
      "0.861\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000, C=0.1)\n",
    "lr.fit(X_train3, y_train2)\n",
    "print(lr.score(X_train3, y_train2))\n",
    "print(lr.score(X_test3, y_test2)) # test data로 보니 호/불호를 맞추는 확률이 86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11327"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'I saw this not too long ago, and I must say: This movie is terrible. I watch crappy movies for fun. Scarecreow is not fun. Scarecrow is stupid. You have an incredibly corny villain that enjoys screaming awful puns as he kills his victims(actually worse than the one contained in this sentence). He has his hard luck story that he uses to justify his killings. \"Everyone picks on me. The only girl that thinks I\\'m not trailer-trash likes one of the guys that pick on me. I want to kill everybody. Wah.\" OK, I\\'m exaggerating. But the premise to this movie alone is enough to put it near the bottom of the list of crappy movies.  Adding to what I just said, the kid\\'s mom is promiscuous, he walks in on his mother and her current boyfriend getting it on, mom\\'s boyfriend tells him to leave, kid refuses, insisting that he isn\\'t going to leave his own house. Boyfriend chases kid into corn field. He kills kid right in front of mom, mom screams in terror, boyfriend is like, \"OMG! I didn\\'t mean to!\" Then he tells mom not to say anything to the police about it. Kid was killed under a scarecrow, though. So, like any kid who gets murdered under a scarecrow, he comes back as a killer scarecrow with a vengeance. His victims \"haven\\'t been stalked like this before...\" (Scarecrow\\'s official tag line)  To make matters worse, this movie was filmed in a whopping 8 days. That\\'s right, 8 days. I was going to give this movie a 2, because in spite of itself, it has one or two redeeming moments. (They\\'re spoilers, so I won\\'t spoil it for you, if you actually want to see this crap.) I could have somewhat forgiven the bad acting, the horrible special effects, the abysmal script, and the bad camera work, but I simply have no respect for lack of effort on that level.  This movie isn\\'t nearly as good as I\\'m making it out to be. If you want to see an example of how not to make a movie, or if you enjoy watching bad movies, like I do, then watch this at your own risk. Everyone else should stay a safe distance away from this movie at all times.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rather',\n",
       " 'yours',\n",
       " 'along',\n",
       " 'for',\n",
       " 'at',\n",
       " 'ours',\n",
       " 'move',\n",
       " 'that',\n",
       " 'were',\n",
       " 'fifty']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS # 불용어, 의미를 갖지 않는 단어들, 굳이 써도 되지 않는 단어들\n",
    "\n",
    "list(ENGLISH_STOP_WORDS)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=5, stop_words=ENGLISH_STOP_WORDS) # 기존 불용어 세트를\n",
    "# cv = CountVectorizer(min_df=5, stop_words='english') # 영어를 불용어로\n",
    "cv.fit(X_train2)\n",
    "X_train3 = cv.transform(X_train2)\n",
    "X_test3 = cv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9846, 0.857)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=1000, C=0.1)\n",
    "lr.fit(X_train3, y_train2)\n",
    "lr.score(X_train3, y_train2), lr.score(X_test3, y_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # 상대빈도\n",
    "\n",
    "tv = TfidfVectorizer(min_df=5) # 단어의 상대빈도 계산 (단일 문서 내 단어빈도 / 이단어가 출연한 문서빈도)\n",
    "tv.fit(X_train2)\n",
    "X_train3 = tv.transform(X_train2)\n",
    "X_test3 = tv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8618)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, C=100)\n",
    "lr.fit(X_train3, y_train2)\n",
    "lr.score(X_train3, y_train2), lr.score(X_test3, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-grams example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = ['The fool doth think he is wise, ', 'but the wise man knows himself to be a fool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # 존재하지 않는 특성을 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'but', 'doth', 'fool', 'he', 'himself', 'is', 'knows', 'man', 'the', 'think', 'to', 'wise']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(test_words)\n",
    "data = cv.transform(test_words)\n",
    "print(cv.get_feature_names())\n",
    "data.toarray() # be가 0,1 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be fool', 'but the', 'doth think', 'fool doth', 'he is', 'himself to', 'is wise', 'knows himself', 'man knows', 'the fool', 'the wise', 'think he', 'to be', 'wise man']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2)) # default= 1,1(min,max) # 2단어씩 # (1,2) -> '한단어', '두단어', '한단어', '두단어'...\n",
    "cv.fit(test_words)\n",
    "data = cv.transform(test_words)\n",
    "print(cv.get_feature_names())\n",
    "data.toarray() # be가 0,1 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(min_df=5, ngram_range=(1,2)) # 적어도 5군데 이상에서 출연해야 뽑겠다 max_df = 5군데 이내(6군데 이상일 시 안뽑음)\n",
    "tv.fit(X_train2)\n",
    "X_train3 = tv.transform(X_train2)\n",
    "X_test3 = tv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9996, 0.8798)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000, C=10)\n",
    "lr.fit(X_train3, y_train2)\n",
    "lr.score(X_train3, y_train2), lr.score(X_test3, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy # 표제어 사전 관리도구 설치\n",
    "# !python -m spacy download en # 영어 표제어 사전 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어간추출기\n",
    "stemmer = nltk.stem.PorterStemmer() # 어간 추출기\n",
    "en_nlp = spacy.load('en') # 영어 표제어 사전 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = u\"Our meeting today was worse than yesterday, I'm scared of meeting the clients tomorrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Our, meeting, today, was, worse, than, yesterday, ,, I, 'm, scared, of, meeting, the, clients, tomorrow]\n",
      "['-PRON-', 'meeting', 'today', 'be', 'bad', 'than', 'yesterday', ',', '-PRON-', 'be', 'scared', 'of', 'meet', 'the', 'client', 'tomorrow']\n",
      "['our', 'meeting', 'today', 'was', 'worse', 'than', 'yesterday', ',', 'i', 'am', 'scared', 'of', 'meeting', 'the', 'clients', 'tomorrow']\n",
      "['our', 'meet', 'today', 'wa', 'wors', 'than', 'yesterday', ',', 'i', 'am', 'scare', 'of', 'meet', 'the', 'client', 'tomorrow']\n"
     ]
    }
   ],
   "source": [
    "spacy_doc = en_nlp(data)\n",
    "print([ token for token in spacy_doc]) # 분리된 단어 목록 출력\n",
    "print([ token.lemma_ for token in spacy_doc]) # 개별 단어의 표제어 출력 -> was/were -> be로 출력 . 가장 정확도 높다\n",
    "print([ token.norm_ for token in spacy_doc]) # 개별 단어의 정규화 표현 출력\n",
    "print([ stemmer.stem(token.norm_) for token in spacy_doc ]) # 개별 단어의 어간 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "regexp = re.compile(r'(?u)\\b\\w\\w+\\b') # 정규 표현식 # 무조건 r을 넣어줘야 한다.\n",
    "\n",
    "def custom_tokenizer(src):\n",
    "    from spacy.tokens import Doc\n",
    "    doc = Doc(en_nlp.vocab, words=regexp.findall(src))\n",
    "    return [ token.lemma_ for token in doc ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=custom_tokenizer, min_df=5)\n",
    "cv.fit(X_train2)\n",
    "X_train3 = cv.transform(X_train2)\n",
    "X_test3 = cv.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9786 0.859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000, C=0.1)\n",
    "lr.fit(X_train3, y_train2)\n",
    "print(lr.score(X_train3, y_train2), lr.score(X_test3, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
